{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f8c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import ImageFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dropout,\n",
    "    MaxPooling2D,\n",
    "    Conv2D,\n",
    "    Activation,\n",
    "    concatenate,\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "results_folder = \"path_to_your_Save_Results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ecb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(r\"Train_and_Vaid_Dataset_path\\*\")\n",
    "\n",
    "img_list = []\n",
    "label_list=[]\n",
    "\n",
    "for folder in folders:\n",
    "    print(folder) \n",
    "    for img in glob.glob(folder+r\"/*.jpg\"):\n",
    "        n= cv2.imread(img)\n",
    "        class_num = folders.index(folder)\n",
    "        label_list.append(class_num)\n",
    "        resized = cv2.resize(n, (299,299), interpolation = cv2.INTER_AREA)\n",
    "        img_list.append(resized)\n",
    "x_train, x_valid , y_train, y_valid  = train_test_split(img_list, label_list, test_size=0.2)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "print (\"training_set\", x_train.shape)\n",
    "print (\"training_set\", y_train.shape)\n",
    "print (\"validation_set\",x_valid.shape)\n",
    "print (\"validation_set\",y_valid.shape)\n",
    "print(\"Train_Folder\",len(x_train))\n",
    "print(\"validation_Folder\",len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders1 = glob.glob(r\"Test_Dataset_path\\*\")\n",
    "\n",
    "img_list1 = []\n",
    "label_list1=[]\n",
    "\n",
    "for folder1 in folders1:\n",
    "    print(folder1) \n",
    "    for img1 in glob.glob(folder1+r\"/*.jpg\"):\n",
    "        n1= cv2.imread(img1)\n",
    "        class_num1 = folders1.index(folder1)\n",
    "        label_list1.append(class_num1)\n",
    "        resized1 = cv2.resize(n1, (299,299), interpolation = cv2.INTER_AREA)\n",
    "        img_list1.append(resized1)\n",
    "\n",
    "x_test, y_test = img_list1, label_list1\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print (\"test_set\",x_test.shape)\n",
    "print (\"test_set\",y_test.shape)\n",
    "print(\"Test_Folder\",len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e048590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftAttention(Layer):\n",
    "    def __init__(self, ch, m, concat_with_x=False, aggregate=False, **kwargs):\n",
    "        self.channels = int(ch)\n",
    "        self.multiheads = m\n",
    "        self.aggregate_channels = aggregate\n",
    "        self.concat_input_with_scaled = concat_with_x\n",
    "        super(SoftAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.i_shape = input_shape\n",
    "        kernel_shape_conv3d = (self.channels, 3, 3) + (1, self.multiheads) # DHWC\n",
    "        self.out_attention_maps_shape = input_shape[0:1] + (self.multiheads,) + input_shape[1:-1]\n",
    "        if self.aggregate_channels == False:\n",
    "            self.out_features_shape = input_shape[:-1] + (input_shape[-1] + (input_shape[-1] * self.multiheads),)\n",
    "        else:\n",
    "            if self.concat_input_with_scaled:\n",
    "                self.out_features_shape = input_shape[:-1] + (input_shape[-1] * 2,)\n",
    "            else:\n",
    "                self.out_features_shape = input_shape\n",
    "\n",
    "        self.kernel_conv3d = self.add_weight(shape=kernel_shape_conv3d,\n",
    "                                              initializer='he_uniform',\n",
    "                                              name='kernel_conv3d')\n",
    "        self.bias_conv3d = self.add_weight(shape=(self.multiheads,),\n",
    "                                            initializer='zeros',\n",
    "                                            name='bias_conv3d')\n",
    "\n",
    "        super(SoftAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        exp_x = K.expand_dims(x, axis=-1)\n",
    "        c3d = K.conv3d(exp_x,\n",
    "                       kernel=self.kernel_conv3d,\n",
    "                       strides=(1, 1, self.i_shape[-1]), padding='same', data_format='channels_last')\n",
    "        conv3d = K.bias_add(c3d, self.bias_conv3d)\n",
    "        conv3d = kl.Activation('selu')(conv3d)  # Using SELU activation here\n",
    "\n",
    "        conv3d = K.permute_dimensions(conv3d, pattern=(0, 4, 1, 2, 3))\n",
    "        conv3d = K.squeeze(conv3d, axis=-1)\n",
    "        conv3d = K.reshape(conv3d, shape=(-1, self.multiheads, self.i_shape[1] * self.i_shape[2]))\n",
    "        softmax_alpha = K.softmax(conv3d, axis=-1)\n",
    "        softmax_alpha = kl.Reshape(target_shape=(self.multiheads, self.i_shape[1], self.i_shape[2]))(softmax_alpha)\n",
    "\n",
    "        if self.aggregate_channels == False:\n",
    "            exp_softmax_alpha = K.expand_dims(softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.permute_dimensions(exp_softmax_alpha, pattern=(0, 2, 3, 1, 4))\n",
    "            x_exp = K.expand_dims(x, axis=-2)\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x_exp])\n",
    "            u = kl.Reshape(target_shape=(self.i_shape[1], self.i_shape[2], u.shape[-1] * u.shape[-2]))(u)\n",
    "        else:\n",
    "            exp_softmax_alpha = K.permute_dimensions(softmax_alpha, pattern=(0, 2, 3, 1))\n",
    "            exp_softmax_alpha = K.sum(exp_softmax_alpha, axis=-1)\n",
    "            exp_softmax_alpha = K.expand_dims(exp_softmax_alpha, axis=-1)\n",
    "            u = kl.Multiply()([exp_softmax_alpha, x])\n",
    "\n",
    "        if self.concat_input_with_scaled:\n",
    "            o = kl.Concatenate(axis=-1)([u, x])\n",
    "        else:\n",
    "            o = u\n",
    "\n",
    "        return [o, softmax_alpha]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [self.out_features_shape, self.out_attention_maps_shape]\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(SoftAttention, self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[MobileNetV3Large]\n",
    "header=[\"MobileNetV3Large\"]\n",
    "for i in range(len(models)):\n",
    "    net = models[i](weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "    conv = net.layers[-1].output\n",
    "    attention_layer, map2 = SoftAttention(aggregate=True, m=16, concat_with_x=False, ch=int(conv.shape[-1]), name='soft_attention')(conv)\n",
    "    attention_layer = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(attention_layer)\n",
    "    conv = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(conv)\n",
    "\n",
    "    conv = concatenate([conv, attention_layer])\n",
    "    conv = Activation('PReLU')(conv)\n",
    "    conv = Dropout(0.2)(conv)\n",
    "\n",
    "    output = GlobalAveragePooling2D()(conv)\n",
    "    output = Dense(2, activation='softmax')(output)\n",
    "    model = Model(inputs=net.input, outputs=output)\n",
    "\n",
    "    batch_size = 8\n",
    "    epochs = 2\n",
    "    opt = SGD(lr=0.0001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "   \n",
    "    weights_filepath = results_folder+'best_weights_{}.h5'.format(header[i])  \n",
    "\n",
    "   \n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=weights_filepath,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',  \n",
    "        mode='max', \n",
    "        save_weights_only=True,  \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "\n",
    "target_names = [\"Fire\",\"Normal\"] \n",
    "classification_report(y_test,y_pred,  target_names=target_names,output_dict=True)\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cdd54c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
